worker_process 1;
# this is the number of worker processes represent
    # 1. the value is the number of worker processes Nginx should create 
    # 2. Each worker process runs independently and can handle its own set of connections

# this configuration directly influences how well it can handle traffic
    # should be tuned according to the servers hardware and exoected traffic load

# in somes cases, its auto => nginx automatically detets the number of CPu cores available on the server and starts a corresponding number of worker nodes

events {
    worker_connections 1024;
}

# worker_connections: the maximum number of connections that each worker process can handle simultaneously
    # 1. the default value is 1024
    # 2. this value should be increased if the server is expected to handle a large number of connections (if 2 worker processes, 2 * 1024)
    # 3. Better performance as per handling traffic but also increases the memory usage

http {

    upstream nodejs_cluster {
        server 127.0.0.1:3001;
        server 127.0.0.1:3002;
        server 127.0.0.1:3003;
    }

    server {
        listen 8080;
        server_name localhost;

        location / {
            proxy_pass http://nodejs_cluster;
        }
    }
}

# http = configuratoin specific to the HTTP and affecting all virtual servers
    # 1. server block
        # defines how Nginx should handle requests for a particular domain or IP address
            # how to listen for connections
            # which dmain or subdomain the configuration applies to
            # how to route the requests
    
        # listen: the port number that Nginx should listen on
            # 1. the default port for HTTP is 80
            # 2. the default port for HTTPS is 443
            # 3. the default port for Nginx is 8080
        
        # server_name: the domain or IP address that the server block should apply to

        # location block:
            #  defines how Nginx should handle requests for a specific URL
            # proxy_pass : tells nginx to "pass" the request to another server, making it act as a reverse proxy

        #upstream block: 
            # defines a group of backend servers that will handle requests forwarded by nginx
            # refers to servers that nginx forwards requests to
            # upstream name is based on the flow of data
            # "upstream servers" = refers to traffic going from a client towards the source or higher level infra, in this xase application server
            # "downstream servers" = refers to traffic going from the source or higher level infra towards the client

