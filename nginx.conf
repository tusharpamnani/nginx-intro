worker_processes 1;
# this is the number of worker processes represent
    # 1. the value is the number of worker processes Nginx should create 
    # 2. Each worker process runs independently and can handle its own set of connections

# this configuration directly influences how well it can handle traffic
    # should be tuned according to the servers hardware and expected traffic load

# in some cases, its auto => nginx automatically detects the number of CPU cores available on the server and starts a corresponding number of worker nodes

events {
    worker_connections 1024;
}

# worker_connections: the maximum number of connections that each worker process can handle simultaneously
    # 1. the default value is 1024
    # 2. this value should be increased if the server is expected to handle a large number of connections (if 2 worker processes, 2 * 1024)
    # 3. Better performance as per handling traffic but also increases the memory usage

http {
    include mime.types;

    upstream nodejs_cluster {
        least_conn; # load balancing algorithm => request sent to the server with the least number of active connections 
        server 127.0.0.1:3001;
        server 127.0.0.1:3002;
        server 127.0.0.1:3003;
    }

    server {
        # listen 8080; # default port for http requests
        listen 443 ssl; # default port for https requests
        server_name localhost;

        ssl_certificate C:/Users/tusha/OneDrive/Desktop/NGINX-introduction/nginx_certs/nginx-selfsigned.crt;
        ssl_certificate_key C:/Users/tusha/OneDrive/Desktop/NGINX-introduction/nginx_certs/nginx-selfsigned.key;

        location / {
            proxy_pass http://nodejs_cluster;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        location = /favicon.ico {
            log_not_found off;
            access_log off;
        }

    }

        server {
        listen 8080;
        server_name localhost;

        location / {
            return 301 https://$host$request_uri; # redirecting http requests to https
        }
    }
}

# http = configuration specific to the HTTP and affecting all virtual servers
    # 1. server block
        # defines how Nginx should handle requests for a particular domain or IP address
            # how to listen for connections
            # which domain or subdomain the configuration applies to
            # how to route the requests
    
        # listen: the port number that Nginx should listen on
            # 1. the default port for HTTP is 80
            # 2. the default port for HTTPS is 443
            # 3. the default port for Nginx is 8080
        
        # server_name: the domain or IP address that the server block should apply to

        # location block:
            #  defines how Nginx should handle requests for a specific URL
            # proxy_pass : tells nginx to "pass" the request to another server, making it act as a reverse proxy

        #upstream block: 
            # defines a group of backend servers that will handle requests forwarded by nginx
            # refers to servers that nginx forwards requests to
            # upstream name is based on the flow of data
            # "upstream servers" = refers to traffic going from a client towards the source or higher level infra, in this case application server
            # "downstream servers" = refers to traffic going from the source or higher level infra towards the client

# when nginx acts as a reverse proxy, the requests coming to the backend servers originate from nginx, not directly from the client.
# as a result, backend servers would see the IP address of the Nginx server as the source of requests, not the client's IP address

# we need to tell nginx to include the corresponding MIME types in the "content type" response header, when sending a file
# this helps the client understand how to process or render a file
